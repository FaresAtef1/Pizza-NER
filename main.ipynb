{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import feature_extractor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constant Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES=23\n",
    "BATCH_SIZE=64\n",
    "EPOCHS=10\n",
    "HIDDEN_SIZE=64\n",
    "VECTOR_SIZE = 768  # Size of word vectors\n",
    "WINDOW_SIZE = 5  # Context window size\n",
    "THREADS = 4  # Number of threads to use for training\n",
    "CUTOFF_FREQ = 1  # Minimum frequency for a word to be included in vocabulary\n",
    "TRAINING_SIZE = 100  \n",
    "TEST_SIZE = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data=utils.read_data(\"../data/fixed_PIZZA_train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = complete_data[:TRAINING_SIZE]\n",
    "corpus, top, decoupled = utils.get_train_dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "entites_output_as_number_labels,intents_output_as_number_labels, input_as_tokenized_string=utils.label_complete_input_bert(corpus, decoupled, top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done1\n",
      "Done2\n",
      "Done3\n"
     ]
    }
   ],
   "source": [
    "reviews_tokens = []\n",
    "with open('../data/food_review.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        reviews_tokens.append(utils.tokenize_string(utils.clean_string(line.strip())))\n",
    "print(\"Done1\")\n",
    "count=0\n",
    "with open('../data/food_review2.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        count+=1\n",
    "        reviews_tokens.append(utils.tokenize_string(utils.clean_string(line.strip())))\n",
    "        if count==TRAINING_SIZE:\n",
    "            break\n",
    "print(\"Done2\")\n",
    "all_trainig = []\n",
    "not_all_corpus, _, _ = utils.get_train_dataset(data)\n",
    "for i in range(len(not_all_corpus)):\n",
    "    all_trainig.append(utils.tokenize_string(utils.clean_string(not_all_corpus[i]))) \n",
    "print(\"Done3\")\n",
    "emb_model = feature_extractor.train_gensim_w2v_model(all_trainig+reviews_tokens, VECTOR_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim.models import Word2Vec, FastText  # For Word2Vec model\n",
    "# emb_model = Word2Vec.load('../embedding_models/word2vec_whole_stemmed.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_model, emb_tokenizer = feature_extractor.init_bert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_trainig+reviews_tokens), +10000+2456446)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('plz', 0.47857165336608887),\n",
       " ('pl', 0.46934911608695984),\n",
       " ('kindli', 0.38020795583724976),\n",
       " ('exponenti', 0.28583502769470215),\n",
       " ('jaan', 0.2755764126777649),\n",
       " ('lije', 0.2750872075557709),\n",
       " ('differenli', 0.27329814434051514),\n",
       " ('poor', 0.26954880356788635),\n",
       " ('hope', 0.2683272957801819),\n",
       " ('ur', 0.2626297175884247)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# emb_model.wv.most_similar('pleas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LargeDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data \n",
    "        self.labels = labels \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "def collate_fn(batch):\n",
    "    sequences, labels = zip(*batch)\n",
    "    #I believe we can transform words into embeddings here\n",
    "    embeddings=[]\n",
    "    # print(sequences)\n",
    "    for seq in sequences:\n",
    "        x=[]\n",
    "        # join seq_string\n",
    "        seq_string = ' '.join(seq)\n",
    "        for token in seq:\n",
    "            emb =feature_extractor.get_word_bert_embedding(token, seq_string, emb_tokenizer, emb_model)\n",
    "            x.append(emb)\n",
    "        embeddings.append(x)\n",
    "    sequences=embeddings\n",
    "    labels = [torch.tensor(label, dtype=torch.long) for label in labels]\n",
    "    padded_labels = pad_sequence(labels, batch_first=True, padding_value=-1)\n",
    "    sequences = [torch.tensor(seq) for seq in sequences]\n",
    "    padded_sequences = pad_sequence(sequences, batch_first=True)\n",
    "    lengths = torch.tensor([len(seq) for seq in sequences], dtype=torch.long)\n",
    "    return padded_sequences, padded_labels, lengths\n",
    "\n",
    "class LargeWordRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(LargeWordRNN, self).__init__()\n",
    "        self.rnn = nn.LSTM(input_size, hidden_size, batch_first=True, bidirectional=True, num_layers=3)\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
    "    \n",
    "    def forward(self, x, lengths):\n",
    "        packed_x = pack_padded_sequence(x, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_out, _ = self.rnn(packed_x)\n",
    "        out, _ = pad_packed_sequence(packed_out, batch_first=True)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking if CUDA is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "None\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(torch.cuda.is_available()) \n",
    "print(torch.version.cuda)\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 3.0540\n",
      "Epoch 2, Loss: 2.9065\n",
      "Epoch 3, Loss: 2.7127\n",
      "Epoch 4, Loss: 2.4520\n",
      "Epoch 5, Loss: 2.2182\n",
      "Epoch 6, Loss: 2.0913\n",
      "Epoch 7, Loss: 2.0993\n",
      "Epoch 8, Loss: 1.9842\n",
      "Epoch 9, Loss: 1.8757\n",
      "Epoch 10, Loss: 1.9668\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "labels = entites_output_as_number_labels\n",
    "\n",
    "dataset = LargeDataset(input_as_tokenized_string, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=True, num_workers=0)\n",
    "\n",
    "model = LargeWordRNN(input_size=VECTOR_SIZE, hidden_size=HIDDEN_SIZE, num_classes=NUM_CLASSES).to(device)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "for epoch in range(EPOCHS): \n",
    "    for padded_sequences, padded_labels, lengths in dataloader:\n",
    "        padded_sequences=padded_sequences.to(device).float()\n",
    "        padded_labels=padded_labels.to(device)\n",
    "        lengths=lengths.to(device).float()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(padded_sequences, lengths).float()\n",
    "        loss = criterion(outputs.view(-1, NUM_CLASSES), padded_labels.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data=complete_data[200000:200010]\n",
    "# print(test_data)\n",
    "# print(\"---------------------------------------------\")\n",
    "# test_corpus,_,_= utils.get_train_dataset(test_data)\n",
    "# print(test_corpus)\n",
    "# test_as_tokenized_string=feature_extractor.list_of_lists(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(test_as_tokenized_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TestLargeDataset(Dataset):\n",
    "#     def __init__(self, data):\n",
    "#         self.data = data \n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         return self.data[idx]\n",
    "\n",
    "# def test_collate_fn(batch):\n",
    "#     sequences = batch\n",
    "#     #I believe we can transform words into embeddings here\n",
    "#     embeddings=[]\n",
    "#     for seq in sequences:\n",
    "#         print(seq)\n",
    "#         x=[]\n",
    "#         for token in seq:\n",
    "#             x.append(emb_model.wv[token])\n",
    "#         embeddings.append(x)\n",
    "#     sequences=embeddings\n",
    "#     sequences = [torch.tensor(seq) for seq in sequences]\n",
    "#     padded_sequences = pad_sequence(sequences, batch_first=True)\n",
    "#     lengths = torch.tensor([len(seq) for seq in sequences], dtype=torch.long)\n",
    "#     return padded_sequences, lengths\n",
    "\n",
    "\n",
    "# test_as_tokenized_string\n",
    "# dataset = TestLargeDataset(test_as_tokenized_string)\n",
    "# dataloader = DataLoader(dataset, batch_size=1, collate_fn=test_collate_fn, shuffle=False, num_workers=0)\n",
    "\n",
    "# for padded_sequences, lengths in dataloader:\n",
    "#     print(\"-------------------------------\")\n",
    "#     padded_sequences=padded_sequences.to(device)\n",
    "#     lengths=lengths.to(device)\n",
    "#     outputs = model(padded_sequences, lengths)\n",
    "#     entity_to_num = {\"I_NUMBER\": 0, \"I_SIZE\": 1, \"I_TOPPING\": 2, \"I_STYLE\": 3, \"I_DRINKTYPE\": 4, \"I_CONTAINERTYPE\": 5, \"I_VOLUME\": 6, \"I_QUANTITY\": 7, \"B_NUMBER\": 8, \"B_SIZE\": 9, \"B_TOPPING\": 10, \"B_STYLE\": 11, \"B_DRINKTYPE\": 12, \"B_CONTAINERTYPE\": 13, \"B_VOLUME\": 14, \"B_QUANTITY\": 15, \"I_NOT_TOPPING\": 16, \"B_NOT_TOPPING\": 17, \"NONE\": 18}\n",
    "#     for i, out in enumerate(outputs[0]):\n",
    "#         num = torch.argmax(out).int().item()\n",
    "#         for key, value in entity_to_num.items():\n",
    "#             if value == num:\n",
    "#                 print(key)\n",
    "#                 break\n",
    "\n",
    "\n",
    "    \n",
    "# #  entity_to_num = {\"I_NUMBER\": 0, \"I_SIZE\": 1, \"I_TOPPING\": 2, \"I_STYLE\": 3, \"I_DRINKTYPE\": 4, \"I_CONTAINERTYPE\": 5, \"I_VOLUME\": 6, \"I_QUANTITY\": 7, \"B_NUMBER\": 8, \"B_SIZE\": 9, \"B_TOPPING\": 10, \"B_STYLE\": 11, \"B_DRINKTYPE\": 12, \"B_CONTAINERTYPE\": 13, \"B_VOLUME\": 14, \"B_QUANTITY\": 15, \"I_NOT_TOPPING\": 16, \"B_NOT_TOPPING\": 17, \"NONE\": 18}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # entity_to_num = {\"I_NUMBER\": 0, \"I_SIZE\": 1, \"I_TOPPING\": 2, \"I_STYLE\": 3, \"I_DRINKTYPE\": 4, \"I_CONTAINERTYPE\": 5, \"I_VOLUME\": 6, \"I_QUANTITY\": 7, \"B_NUMBER\": 8, \"B_SIZE\": 9, \"B_TOPPING\": 10, \"B_STYLE\": 11, \"B_DRINKTYPE\": 12, \"B_CONTAINERTYPE\": 13, \"B_VOLUME\": 14, \"B_QUANTITY\": 15, \"I_NOT_TOPPING\": 16, \"B_NOT_TOPPING\": 17, \"NONE\": 18}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n",
      "-------------------------------\n",
      "Wrong prediction in 0 th sentence at 4 th token\n",
      "Wrong prediction in 0 th sentence at 5 th token\n",
      "Wrong prediction in 0 th sentence at 8 th token\n",
      "Wrong prediction in 0 th sentence at 10 th token\n",
      "Wrong prediction in 0 th sentence at 11 th token\n",
      "Wrong prediction in 0 th sentence at 13 th token\n",
      "Wrong prediction in 0 th sentence at 14 th token\n",
      "Wrong prediction in 0 th sentence at 17 th token\n",
      "Wrong prediction in 0 th sentence at 19 th token\n",
      "Wrong prediction in 0 th sentence at 20 th token\n",
      "Wrong prediction in 0 th sentence at 22 th token\n",
      "Wrong prediction in 0 th sentence at 23 th token\n",
      "Wrong prediction in 0 th sentence at 26 th token\n",
      "Wrong prediction in 0 th sentence at 28 th token\n",
      "Sentence: i want to order two medium pizzas with sausage and black olives and two medium pizzas with pepperoni and extra cheese and three large pizzas with pepperoni and sausage\n",
      "Pred: [22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22]\n",
      "True: [22, 22, 22, 22, 8, 9, 22, 22, 10, 22, 10, 2, 22, 8, 9, 22, 22, 10, 22, 15, 10, 22, 8, 9, 22, 22, 10, 22, 10]\n",
      "-------------------------------------------------\n",
      "Wrong prediction in 1 th sentence at 0 th token\n",
      "Wrong prediction in 1 th sentence at 1 th token\n",
      "Wrong prediction in 1 th sentence at 4 th token\n",
      "Wrong prediction in 1 th sentence at 6 th token\n",
      "Sentence: five medium pizzas with tomatoes and ham\n",
      "Pred: [22, 22, 22, 22, 22, 22, 22]\n",
      "True: [8, 9, 22, 22, 10, 22, 10]\n",
      "-------------------------------------------------\n",
      "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 4, 4, 8, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 18]]\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "dev_data=utils.read_data(\"../data/fixed_PIZZA_dev.json\")\n",
    "dev_corpus, dev_top = utils.get_dev_dataset(dev_data[:2])\n",
    "gold_dev_labels,dev_as_tokenized_string=utils.label_complete_dev_bert(dev_corpus, dev_top)\n",
    "\n",
    "class TestLargeDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "def test_collate_fn(batch):\n",
    "    sequences = batch\n",
    "    embeddings=[]\n",
    "    for seq in sequences:\n",
    "        x=[]\n",
    "        seq_string = ' '.join(seq)\n",
    "        for token in seq:\n",
    "            emb =feature_extractor.get_word_bert_embedding(token, seq_string, emb_tokenizer, emb_model)\n",
    "            x.append(emb)\n",
    "        embeddings.append(x)\n",
    "    sequences=embeddings\n",
    "    sequences = [torch.tensor(seq) for seq in sequences]\n",
    "    padded_sequences = pad_sequence(sequences, batch_first=True)\n",
    "    lengths = torch.tensor([len(seq) for seq in sequences], dtype=torch.long)\n",
    "    return padded_sequences, lengths\n",
    "\n",
    "dev_dataset = TestLargeDataset(dev_as_tokenized_string)\n",
    "dataloader = DataLoader(dev_dataset, batch_size=1, collate_fn=test_collate_fn, shuffle=False, num_workers=0)\n",
    "model_output=[]\n",
    "for padded_sequences, lengths in dataloader:\n",
    "    print(\"-------------------------------\")\n",
    "    labels = []\n",
    "    padded_sequences=padded_sequences.to(device).float()\n",
    "    lengths=lengths.to(device).float()\n",
    "    outputs = model(padded_sequences, lengths)\n",
    "    entity_to_num = {\"I_NUMBER\": 0, \"I_SIZE\": 1, \"I_TOPPING\": 2, \"I_STYLE\": 3, \"I_DRINKTYPE\": 4, \"I_CONTAINERTYPE\": 5, \"I_VOLUME\": 6, \"I_QUANTITY\": 7, \"B_NUMBER\": 8, \"B_SIZE\": 9, \"B_TOPPING\": 10, \"B_STYLE\": 11, \"B_DRINKTYPE\": 12, \"B_CONTAINERTYPE\": 13, \"B_VOLUME\": 14, \"B_QUANTITY\": 15, \"I_NOT_TOPPING\": 16, \"B_NOT_TOPPING\": 17,\"I_NOT_STYLE\": 18, \"B_NOT_STYLE\": 19, \"B_NOT_QUANTITY\": 20, \"I_NOT_QUANTITY\": 21, \"NONE\": 22}\n",
    "    for i, out in enumerate(outputs[0]):\n",
    "        num = torch.argmax(out).int().item()\n",
    "        labels.append(num)\n",
    "    model_output.append(labels)\n",
    "\n",
    "confusion_matrix, accuracy=utils.calc_accuracy(dev_corpus,model_output, gold_dev_labels)\n",
    "print(confusion_matrix)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import os\n",
    "# import opendatasets as od\n",
    "# # ! pip install opendatasets\n",
    "# # Assign the Kaggle data set URL into variable\n",
    "# dataset = 'https://www.kaggle.com/datasets/ghaithqoudeiamti/pizza-dataset?select=food_review2.txt'\n",
    "# # Using opendatasets let's download the data sets\n",
    "# od.download(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = pickle.load(open('../models/model_1m.pk1' , 'rb'))\n",
    "# model = torch.load('../models/model_1m.pk1', map_location=torch.device('cpu'))\n",
    "model = torch.load('../models/model_1m.pk1', map_location=torch.device('cpu'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1956451\n",
      "{\"train.SRC\": \"i'd like a pizza with cheeseburger sausages and garlic powder\", \"train.EXR\": \"(ORDER (PIZZAORDER (NUMBER 1 ) (TOPPING CHEESEBURGER ) (TOPPING SAUSAGE ) (TOPPING GARLIC_POWDER ) ) )\", \"train.TOP\": \"(ORDER i'd like (PIZZAORDER (NUMBER a ) pizza with (TOPPING cheeseburger ) (TOPPING sausages ) and (TOPPING garlic powder ) ) )\", \"train.TOP-DECOUPLED\": \"(ORDER (PIZZAORDER (NUMBER a ) (TOPPING cheeseburger ) (TOPPING sausages ) (TOPPING garlic powder ) ) )\"},\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "pattern = re.compile(r'(?<=train.TOP).*\\(TOPPING [a-z]* \\) \\(TOPPING [a-z]* \\).*(?=train.TOP-DECOUPLED)')\n",
    "\n",
    "with open('../data/fixed_PIZZA_train.json', 'r') as file:\n",
    "    for i, line in enumerate(file):\n",
    "        # Process each line\n",
    "        matches = pattern.findall(line)\n",
    "        if matches:\n",
    "            print(i)\n",
    "            print(line)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
