{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this notebook we will do some preprocessing on the data and tokenization\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "def clean_string(input_string):\n",
    "    \"\"\"\n",
    "    Cleans the input string by removing special characters, and unnecessary punctuation.\n",
    "\n",
    "    Args:\n",
    "        input_string: The string to be cleaned.\n",
    "\n",
    "    Returns:\n",
    "        The cleaned string.\n",
    "    \"\"\"\n",
    "    # Remove special characters and unnecessary punctuation\n",
    "    # TODO: Add more special characters as needed to be excluded\n",
    "    cleaned_string = re.sub(r\"[^\\w\\s'-]\", \"\", input_string)  # Keeps only alphanumeric characters and spaces and apostrophes and hyphens\n",
    "    cleaned_string = cleaned_string.lower()\n",
    "    # Remove extra whitespace\n",
    "    cleaned_string = re.sub(r\"\\s+\", \" \", cleaned_string).strip()\n",
    "    return cleaned_string\n",
    "\n",
    "def tokenize_string(input_string):\n",
    "    \"\"\"\n",
    "    Tokenizes the input string into tokens.\n",
    "    \n",
    "    Args:\n",
    "        input_string: The string to be tokenized.\n",
    "\n",
    "    Returns:\n",
    "        A list of tokens.\n",
    "    \"\"\"\n",
    "    tokens = nltk.word_tokenize(input_string)\n",
    "    return tokens\n",
    "\n",
    "def label_tokens1(input_tokens, structure_text):\n",
    "    \"\"\"\n",
    "    Labels the input text based on a structured representation and a list of attributes.\n",
    "\n",
    "    Args:\n",
    "        input_tokens: The tokenized input text.\n",
    "        structure_text: The structured text containing attributes and their values.\n",
    "\n",
    "    Returns:\n",
    "        A list of tuples where each token in the input text is paired with its corresponding label.\n",
    "    \"\"\"\n",
    "    attribute_values = {\"NUMBER\", \"SIZE\", \"TOPPING\", \"STYLE\", \"DRINKTYPE\", \"CONTAINERTYPE\", \"VOLUME\", \"QUANTITY\"}\n",
    "    structure_map = {}\n",
    "    for attribute in attribute_values:\n",
    "        # Match the attribute and its value in the structure text\n",
    "        pattern = r\"\\(\\s*\"+ attribute + r\"\\s+([^\\)]*)\\s*\\)\"\n",
    "        matches = re.finditer(pattern, structure_text)\n",
    "        for match in matches:\n",
    "            value = match.group(1).strip()\n",
    "            # Special handling for TOPPING with \"not\" before it\n",
    "            if attribute == \"TOPPING\":\n",
    "                preceding_text = structure_text[:match.start()]\n",
    "                if re.search(r\"\\bNOT\\b\", preceding_text, re.IGNORECASE):\n",
    "                    attribute = \"NOT_TOPPING\"\n",
    "            structure_map[value] = attribute\n",
    "    labeled_output = []\n",
    "    for token in input_tokens:\n",
    "        label = \"NONE\"\n",
    "        if token in structure_map:\n",
    "            label = structure_map[token]\n",
    "        # else check if it is part of the key\n",
    "        else:\n",
    "            for key in structure_map.keys():\n",
    "                if token in key.split():\n",
    "                    label = structure_map[key]\n",
    "                    break\n",
    "        labeled_output.append((token, label))\n",
    "    return labeled_output\n",
    "\n",
    "def label_tokens2(input_tokens, structure_tokens):\n",
    "    \"\"\"\n",
    "    Labels the input text based on a structured representation and a list of attributes.\n",
    "\n",
    "    Args:\n",
    "        input_tokens: The tokenized input text.\n",
    "        structure_text: The structured text containing attributes and their values.\n",
    "\n",
    "    Returns:\n",
    "        A list of tuples where each token in the input text is paired with its corresponding label.\n",
    "    \"\"\"\n",
    "    attributes = [\"PIZZAORDER\", \"DRINKORDER\", \"COMPLEX_TOPPING\"]\n",
    "    execluded = {\"NUMBER\", \"SIZE\", \"TOPPING\", \"STYLE\", \"DRINKTYPE\", \"CONTAINERTYPE\", \"VOLUME\", \"QUANTITY\"}\n",
    "    curr = \"NONE\"\n",
    "    # I will also keep tracking \"(\" and \")\" to know when to change the current attribute to NONE\n",
    "    parentheses =0\n",
    "    labels_mapping = {}\n",
    "    for token in structure_tokens:\n",
    "        if token in attributes:\n",
    "            curr = token\n",
    "        elif token == \"(\":\n",
    "            parentheses += 1\n",
    "        elif token == \")\":\n",
    "            parentheses -= 1\n",
    "            if parentheses == 1:\n",
    "                curr = \"NONE\"\n",
    "        elif token not in execluded:\n",
    "            labels_mapping[token] = curr\n",
    "    labeled_output = []\n",
    "    for token in input_tokens:\n",
    "        label = \"NONE\"\n",
    "        if token in labels_mapping:\n",
    "            label = labels_mapping[token]\n",
    "        labeled_output.append((token, label))\n",
    "    return labeled_output\n",
    "\n",
    "def label_input(input_text, structure_text1, structure_text2):\n",
    "    \"\"\"\n",
    "    It is a similar function to the previous one, but it is used for adding another layer for the input\n",
    "    which is the preprocessing of the input text and then tokenizing it.\n",
    "\n",
    "    Args:\n",
    "        input_text: The raw input text.\n",
    "        structure_text1: The structured text containing attributes and their values. (train.TOP-DECOUPLED)\n",
    "        structure_text2: The structured text containing attributes and their values. (train.TOP)\n",
    "    \n",
    "    Returns:\n",
    "        2 lists of tuples where each token in the input text is paired with its corresponding label.\n",
    "    \"\"\"\n",
    "    cleaned_text = clean_string(input_text)\n",
    "    input_tokens = tokenize_string(cleaned_text)\n",
    "    labeled_output1 = label_tokens1(input_tokens, structure_text1)\n",
    "    structure2_tokens = tokenize_string(structure_text2)\n",
    "    labeled_output2 = label_tokens2(input_tokens, structure2_tokens)\n",
    "    return labeled_output1, labeled_output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------1------------------\n",
      "1  [('i', 'NONE'), (\"'d\", 'NONE'), ('like', 'NONE'), ('a', 'NUMBER'), ('large', 'SIZE'), ('vegetarian', 'STYLE'), ('pizza', 'NONE')]\n",
      "2  [('i', 'NONE'), (\"'d\", 'NONE'), ('like', 'NONE'), ('a', 'PIZZAORDER'), ('large', 'PIZZAORDER'), ('vegetarian', 'PIZZAORDER'), ('pizza', 'PIZZAORDER')]\n",
      "------------------2------------------\n",
      "1  [('a', 'NUMBER'), ('20', 'VOLUME'), ('fl', 'VOLUME'), ('ounce', 'VOLUME'), ('cherry', 'DRINKTYPE'), ('coke', 'DRINKTYPE'), ('bottle', 'CONTAINERTYPE')]\n",
      "2  [('a', 'DRINKORDER'), ('20', 'DRINKORDER'), ('fl', 'DRINKORDER'), ('ounce', 'DRINKORDER'), ('cherry', 'DRINKORDER'), ('coke', 'DRINKORDER'), ('bottle', 'DRINKORDER')]\n",
      "------------------3------------------\n",
      "1  [('four', 'NUMBER'), ('pizzas', 'NONE'), ('with', 'NONE'), ('american', 'TOPPING'), ('cheese', 'TOPPING'), ('and', 'NONE'), ('also', 'NONE'), ('three', 'NUMBER'), ('cans', 'CONTAINERTYPE'), ('of', 'NONE'), ('ice', 'DRINKTYPE'), ('tea', 'DRINKTYPE'), ('and', 'NONE'), ('three', 'NUMBER'), ('regular', 'SIZE'), ('san', 'DRINKTYPE'), ('pellegrinos', 'DRINKTYPE')]\n",
      "2  [('four', 'PIZZAORDER'), ('pizzas', 'PIZZAORDER'), ('with', 'PIZZAORDER'), ('american', 'PIZZAORDER'), ('cheese', 'PIZZAORDER'), ('and', 'NONE'), ('also', 'NONE'), ('three', 'DRINKORDER'), ('cans', 'DRINKORDER'), ('of', 'DRINKORDER'), ('ice', 'DRINKORDER'), ('tea', 'DRINKORDER'), ('and', 'NONE'), ('three', 'DRINKORDER'), ('regular', 'DRINKORDER'), ('san', 'DRINKORDER'), ('pellegrinos', 'DRINKORDER')]\n",
      "------------------4------------------\n",
      "1  [('i', 'NONE'), ('want', 'NONE'), ('one', 'NUMBER'), ('personal', 'SIZE'), ('-', 'SIZE'), ('size', 'SIZE'), ('pie', 'NONE'), ('without', 'NONE'), ('any', 'NONE'), ('carrots', 'NOT_TOPPING')]\n",
      "2  [('i', 'NONE'), ('want', 'NONE'), ('one', 'PIZZAORDER'), ('personal', 'PIZZAORDER'), ('-', 'PIZZAORDER'), ('size', 'PIZZAORDER'), ('pie', 'PIZZAORDER'), ('without', 'PIZZAORDER'), ('any', 'PIZZAORDER'), ('carrots', 'PIZZAORDER')]\n",
      "------------------5------------------\n",
      "1  [('can', 'NONE'), ('i', 'NONE'), ('have', 'NONE'), ('one', 'NUMBER'), ('high', 'STYLE'), ('rise', 'STYLE'), ('dough', 'STYLE'), ('pie', 'NONE'), ('with', 'NONE'), ('american', 'TOPPING'), ('cheese', 'TOPPING'), ('and', 'NONE'), ('a', 'QUANTITY'), ('lot', 'QUANTITY'), ('of', 'QUANTITY'), ('meatball', 'TOPPING')]\n",
      "2  [('can', 'NONE'), ('i', 'NONE'), ('have', 'NONE'), ('one', 'PIZZAORDER'), ('high', 'PIZZAORDER'), ('rise', 'PIZZAORDER'), ('dough', 'PIZZAORDER'), ('pie', 'PIZZAORDER'), ('with', 'PIZZAORDER'), ('american', 'PIZZAORDER'), ('cheese', 'PIZZAORDER'), ('and', 'PIZZAORDER'), ('a', 'COMPLEX_TOPPING'), ('lot', 'COMPLEX_TOPPING'), ('of', 'COMPLEX_TOPPING'), ('meatball', 'COMPLEX_TOPPING')]\n",
      "------------------6------------------\n",
      "1  [('i', 'NONE'), (\"'d\", 'NONE'), ('like', 'NONE'), ('a', 'NUMBER'), ('lunch', 'SIZE'), ('-', 'SIZE'), ('sized', 'SIZE'), ('pie', 'NONE'), ('without', 'NONE'), ('alfredo', 'NOT_TOPPING'), ('chicken', 'NOT_TOPPING')]\n",
      "2  [('i', 'NONE'), (\"'d\", 'NONE'), ('like', 'NONE'), ('a', 'PIZZAORDER'), ('lunch', 'PIZZAORDER'), ('-', 'PIZZAORDER'), ('sized', 'PIZZAORDER'), ('pie', 'PIZZAORDER'), ('without', 'PIZZAORDER'), ('alfredo', 'PIZZAORDER'), ('chicken', 'PIZZAORDER')]\n",
      "------------------7------------------\n",
      "1  [('i', 'NONE'), (\"'d\", 'NONE'), ('like', 'NONE'), ('a', 'NUMBER'), ('lunch', 'SIZE'), ('-', 'SIZE'), ('sized', 'SIZE'), ('pie', 'NONE'), ('without', 'NONE'), ('alfredo', 'NOT_TOPPING'), ('chicken', 'NOT_TOPPING'), ('or', 'NONE'), ('beef', 'NOT_TOPPING')]\n",
      "2  [('i', 'NONE'), (\"'d\", 'NONE'), ('like', 'NONE'), ('a', 'PIZZAORDER'), ('lunch', 'PIZZAORDER'), ('-', 'PIZZAORDER'), ('sized', 'PIZZAORDER'), ('pie', 'PIZZAORDER'), ('without', 'PIZZAORDER'), ('alfredo', 'PIZZAORDER'), ('chicken', 'PIZZAORDER'), ('or', 'PIZZAORDER'), ('beef', 'PIZZAORDER')]\n"
     ]
    }
   ],
   "source": [
    "out1,out2 = label_input(\"i'd like a large vegetarian pizza\", \"(ORDER (PIZZAORDER (NUMBER a ) (SIZE large ) (STYLE vegetarian ) ) )\",\"(ORDER i'd like (PIZZAORDER (NUMBER a ) (SIZE large ) (STYLE vegetarian ) pizza ) )\")\n",
    "print(\"------------------1------------------\")\n",
    "print(\"1 \",out1)\n",
    "print(\"2 \",out2)\n",
    "out1, out2 = label_input(\"a 20 fl ounce cherry coke bottle\", \"(ORDER (DRINKORDER (NUMBER a ) (VOLUME 20 fl ounce ) (DRINKTYPE cherry coke ) (CONTAINERTYPE bottle ) ) )\", \"(ORDER (DRINKORDER (NUMBER a ) (VOLUME 20 fl ounce ) (DRINKTYPE cherry coke ) (CONTAINERTYPE bottle ) ) )\")\n",
    "print(\"------------------2------------------\")\n",
    "print(\"1 \",out1)\n",
    "print(\"2 \",out2)\n",
    "out1, out2 = label_input(\"four pizzas with american cheese and also three cans of ice tea and three regular san pellegrinos\", \"(ORDER (PIZZAORDER (NUMBER four ) (TOPPING american cheese ) ) (DRINKORDER (NUMBER three ) (CONTAINERTYPE cans ) (DRINKTYPE ice tea ) ) (DRINKORDER (NUMBER three ) (SIZE regular ) (DRINKTYPE san pellegrinos ) ) )\", \"(ORDER (PIZZAORDER (NUMBER four ) pizzas with (TOPPING american cheese ) ) and also (DRINKORDER (NUMBER three ) (CONTAINERTYPE cans ) of (DRINKTYPE ice tea ) ) and (DRINKORDER (NUMBER three ) (SIZE regular ) (DRINKTYPE san pellegrinos ) ) )\")\n",
    "print(\"------------------3------------------\")\n",
    "print(\"1 \",out1)\n",
    "print(\"2 \",out2)\n",
    "out1, out2 = label_input(\"i want one personal - size pie without any carrots\", \"(ORDER (PIZZAORDER (NUMBER one ) (SIZE personal - size ) (NOT (TOPPING carrots ) ) ) )\", \"(ORDER i want (PIZZAORDER (NUMBER one ) (SIZE personal - size ) pie without any (NOT (TOPPING carrots ) ) ) )\")\n",
    "print(\"------------------4------------------\")\n",
    "print(\"1 \",out1)\n",
    "print(\"2 \",out2)\n",
    "out1, out2 = label_input(\"can i have one high rise dough pie with american cheese and a lot of meatball\", \"(ORDER (PIZZAORDER (NUMBER one ) (STYLE high rise dough ) (TOPPING american cheese ) (COMPLEX_TOPPING (QUANTITY a lot of ) (TOPPING meatball ) ) ) )\", \"(ORDER can i have (PIZZAORDER (NUMBER one ) (STYLE high rise dough ) pie with (TOPPING american cheese ) and (COMPLEX_TOPPING (QUANTITY a lot of ) (TOPPING meatball ) ) ) )\") \n",
    "print(\"------------------5------------------\")\n",
    "print(\"1 \",out1)\n",
    "print(\"2 \",out2)\n",
    "out1, out2 = label_input(\"i'd like a lunch - sized pie without alfredo chicken\", \"(ORDER (PIZZAORDER (NUMBER a ) (SIZE lunch - sized ) (NOT (TOPPING alfredo chicken ) ) ) )\", \"(ORDER i'd like (PIZZAORDER (NUMBER a ) (SIZE lunch - sized ) pie without (NOT (TOPPING alfredo chicken ) ) ) )\") \n",
    "print(\"------------------6------------------\")\n",
    "print(\"1 \",out1)\n",
    "print(\"2 \",out2)\n",
    "out1, out2 = label_input(\"i'd like a lunch - sized pie without alfredo chicken or beef\", \"(ORDER (PIZZAORDER (NUMBER a ) (SIZE lunch - sized ) (NOT (TOPPING alfredo chicken ) )(NOT (TOPPING beef ) ) ) )\", \"(ORDER i'd like (PIZZAORDER (NUMBER a ) (SIZE lunch - sized ) pie without (NOT (TOPPING alfredo chicken ) ) or (NOT (TOPPING beef ) ) ) )\") \n",
    "print(\"------------------7------------------\")\n",
    "print(\"1 \",out1)\n",
    "print(\"2 \",out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
